{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e2193cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5297, 148)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# to make a clean output\n",
    "np.seterr(over='ignore', divide='ignore', invalid='ignore')\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "df = pd.read_csv(\"cleaned_data.csv\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02a4f677",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"hospital_expire_flag\"\n",
    "\n",
    "# Columns we don't want to use as features\n",
    "id_cols = [\n",
    "    \"subject_id\", \"hadm_id\", \"stay_id\",\n",
    "    \"Group_Name\", \"Term\", \"DOID\", \"ICD10Code\"\n",
    "]\n",
    "\n",
    "time_cols = [\n",
    "    \"dod\", \"admittime\", \"dischtime\",\n",
    "    \"icu_intime\", \"icu_outtime\",\n",
    "    \"admittime_1\", \"dischtime_1\", \"deathtime\", \"dod_1\"\n",
    "]\n",
    "\n",
    "leak_cols = [\"los_hospital\", \"los_icu\"]\n",
    "\n",
    "drop_cols = id_cols + time_cols + leak_cols + [target]\n",
    "\n",
    "# define the feature matrix and respond vector\n",
    "X = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
    "y = df[target]\n",
    "# convert the subject id to patient index\n",
    "codes, uniques = pd.factorize(df['subject_id'])\n",
    "\n",
    "# make sure all the columns of the feature matrix is numeric for regression\n",
    "bool_cols = X.select_dtypes(\"bool\").columns\n",
    "X[bool_cols] = X[bool_cols].astype(int)\n",
    "cat_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "X_encoded = pd.get_dummies(X, columns=cat_cols, drop_first=True)\n",
    "feature_names = X_encoded.columns.to_list()\n",
    "X = X_encoded.to_numpy(dtype=float)\n",
    "y = y.to_numpy(dtype=float)\n",
    "ids = codes.astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38c7eeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "def loglik_hier(beta, z, b, X, y, ids):\n",
    "    \"\"\"\n",
    "    logistic log-likelihood\n",
    "    \"\"\"\n",
    "    beta_eff = beta * z\n",
    "    eta = X @ beta_eff + b[ids]\n",
    "    return np.sum(y * eta - np.log1p(np.exp(eta)))\n",
    "\n",
    "\n",
    "def update_sigma2_b(b_curr, a0=0.001, b0=0.001, rng=None):\n",
    "    \"\"\"\n",
    "    Gamma conjugate posterior\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "    n_id = b_curr.shape[0]\n",
    "    a_post = a0 + n_id / 2.0\n",
    "    b_post = b0 + 0.5 * np.sum(b_curr**2)\n",
    "    gamma_sample = rng.gamma(shape=a_post, scale=1.0 / b_post)\n",
    "    sigma2_b = 1.0 / gamma_sample\n",
    "    return sigma2_b\n",
    "\n",
    "\n",
    "def flip_z_hier(z_curr, beta_curr, b_curr, X, y, ids, rng=None):\n",
    "    \"\"\"\n",
    "    A single update for z\n",
    "    \"\"\"\n",
    "    if rng is None:\n",
    "        rng = np.random.default_rng()\n",
    "\n",
    "    p = len(z_curr)\n",
    "    z = z_curr.copy()\n",
    "\n",
    "    for j in rng.permutation(p):\n",
    "        z0 = z.copy()\n",
    "        z1 = z.copy()\n",
    "        # propose the flip\n",
    "        z0[j] = 0.0\n",
    "        z1[j] = 1.0\n",
    "        # compute the corresponding likelihood\n",
    "        ll0 = loglik_hier(beta_curr, z0, b_curr, X, y, ids)\n",
    "        ll1 = loglik_hier(beta_curr, z1, b_curr, X, y, ids)\n",
    "        # compute the full conditional probability\n",
    "        log_odds = ll1 - ll0\n",
    "        p1 = expit(log_odds)\n",
    "\n",
    "        z[j] = rng.binomial(1, p1)\n",
    "\n",
    "    return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe1f3eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from polyagamma import random_polyagamma\n",
    "from numpy.random import default_rng\n",
    "\n",
    "def pg_update_beta_b(beta_curr, b_curr, z_curr, X, Z_mat, y,\n",
    "                     sigma0=100.0, sigma2_b=1.0, rng=None):\n",
    "    \"\"\"\n",
    "    A single step for Polya Gamma Data Augmentation step\n",
    "    \"\"\"\n",
    "\n",
    "    if rng is None:\n",
    "        rng = default_rng()\n",
    "\n",
    "    n, p = X.shape\n",
    "    n_id = Z_mat.shape[1]\n",
    "\n",
    "    # stack the covariate matrix and the id matrix\n",
    "    X_z = X * z_curr\n",
    "    X_tilde = np.hstack([X_z, Z_mat])\n",
    "\n",
    "    # combine the two priors to form the precision matrix\n",
    "    prec_beta = np.full(p, 1.0 / sigma0**2)\n",
    "    prec_b = np.full(n_id, 1.0 / sigma2_b)\n",
    "    Sigma0_inv = np.diag(np.concatenate([prec_beta, prec_b]))\n",
    "\n",
    "    # sample latent variable\n",
    "    beta_eff = beta_curr * z_curr\n",
    "    eta = X @ beta_eff + Z_mat @ b_curr\n",
    "    eta = np.clip(eta, -30.0, 30.0)\n",
    "    omega = random_polyagamma(1.0, np.asarray(eta, dtype=float))\n",
    "\n",
    "    # other parameters for sampling beta and b\n",
    "    kappa = y - 0.5\n",
    "    WX = X_tilde * omega[:, None]\n",
    "    XtWX = X_tilde.T @ WX\n",
    "\n",
    "    # precision matrix\n",
    "    Q = XtWX + Sigma0_inv\n",
    "    I_q = np.eye(Q.shape[0])\n",
    "\n",
    "    # try Cholesky with increasing ridge if needed\n",
    "    eps = 1e-6\n",
    "    for _ in range(6):\n",
    "        try:\n",
    "            Q_reg = Q + eps * I_q\n",
    "            R = np.linalg.cholesky(Q_reg) \n",
    "            break\n",
    "        except np.linalg.LinAlgError:\n",
    "            eps *= 10.0\n",
    "\n",
    "    # mean: solve Q_reg * m = X_tilde^T kappa\n",
    "    rhs = X_tilde.T @ kappa\n",
    "    m_om = np.linalg.solve(Q_reg, rhs)\n",
    "\n",
    "    # sample from MNV via Cholesky\n",
    "    z = rng.normal(size=Q_reg.shape[0])\n",
    "    u = np.linalg.solve(R.T, z)\n",
    "    theta_new = m_om + u\n",
    "\n",
    "    beta_new = theta_new[:p]\n",
    "    b_new = theta_new[p:]\n",
    "\n",
    "    return beta_new, b_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e26bd540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mcmc_pg_hier(X, y, ids,\n",
    "                     sigma0=100.0,\n",
    "                     n_iter=5000,\n",
    "                     burn_in=1000,\n",
    "                     a0=0.001, b0=0.001,\n",
    "                     seed=111):\n",
    "    \"\"\"\n",
    "    X: (n, p) numpy array\n",
    "    y: (n,) numpy array, 0/1\n",
    "    ids: (n,) numpy array of subject indices, should be converted 0,...,n_id-1\n",
    "    \"\"\"\n",
    "    rng = default_rng(seed)\n",
    "\n",
    "    n, p = X.shape\n",
    "    n_id = len(np.unique(ids))\n",
    "\n",
    "    # construct the id dummy variable\n",
    "    Z_mat = np.zeros((n, n_id), dtype=float)\n",
    "    Z_mat[np.arange(n), ids] = 1.0\n",
    "\n",
    "    # initialize parameters\n",
    "    beta_curr = np.zeros(p)\n",
    "    z_curr = np.ones(p)\n",
    "    sigma2_b = 1.0\n",
    "    b_curr = rng.normal(loc=0.0, scale=np.sqrt(sigma2_b), size=n_id)\n",
    "\n",
    "    B_save = np.zeros((n_iter, p)) # beta parameters\n",
    "    Z_save = np.zeros((n_iter, p)) # feature selection indicator\n",
    "    sigma2_b_save = np.zeros(n_iter)\n",
    "\n",
    "    for it in range(n_iter):\n",
    "        # update coefs by PG method\n",
    "        beta_curr, b_curr = pg_update_beta_b(\n",
    "            beta_curr, b_curr, z_curr,\n",
    "            X, Z_mat, y,\n",
    "            sigma0=sigma0,\n",
    "            sigma2_b=sigma2_b,\n",
    "            rng=rng\n",
    "        )\n",
    "\n",
    "        # update sigma_b^2\n",
    "        sigma2_b = update_sigma2_b(b_curr, a0=a0, b0=b0, rng=rng)\n",
    "\n",
    "        # update z\n",
    "        z_curr = flip_z_hier(z_curr, beta_curr, b_curr, X, y, ids, rng=rng)\n",
    "\n",
    "        # save\n",
    "        B_save[it, :] = beta_curr\n",
    "        Z_save[it, :] = z_curr\n",
    "        sigma2_b_save[it] = sigma2_b\n",
    "\n",
    "        if (it + 1) % 1000 == 0:\n",
    "            print(f\"iter = {it+1} / {n_iter}\")\n",
    "\n",
    "    # discard the burnin period\n",
    "    keep = np.arange(burn_in, n_iter)\n",
    "\n",
    "    return {\n",
    "        \"B\": B_save[keep, :],\n",
    "        \"Z\": Z_save[keep, :],\n",
    "        \"sigma2_b\": sigma2_b_save[keep]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "433d615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "subjects = df[\"subject_id\"].unique()\n",
    "rng = np.random.default_rng(638)\n",
    "# assign the subject ids to random order and pick 80%\n",
    "rng.shuffle(subjects)\n",
    "n_train_subj = int(0.8 * len(subjects))\n",
    "# split the train and test ids\n",
    "train_subj = subjects[:n_train_subj]\n",
    "test_subj = subjects[n_train_subj:]\n",
    "\n",
    "# extract the corresponding patients' records\n",
    "train_mask = df[\"subject_id\"].isin(train_subj).values\n",
    "test_mask = ~train_mask\n",
    "# split the train and test data\n",
    "X_train = X[train_mask, :]\n",
    "y_train = y[train_mask]\n",
    "X_test = X[test_mask, :]\n",
    "y_test = y[test_mask]\n",
    "\n",
    "# extract the train and test ids in order\n",
    "codes_train, uniq_train = pd.factorize(df.loc[train_mask, \"subject_id\"])\n",
    "codes_test, uniq_test = pd.factorize(df.loc[test_mask, \"subject_id\"])\n",
    "# turn them to id index\n",
    "ids_train = codes_train.astype(int)\n",
    "ids_test  = codes_test.astype(int)\n",
    "\n",
    "# standardize\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f26650e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter = 1000 / 8000\n",
      "iter = 2000 / 8000\n",
      "iter = 3000 / 8000\n",
      "iter = 4000 / 8000\n",
      "iter = 5000 / 8000\n",
      "iter = 6000 / 8000\n",
      "iter = 7000 / 8000\n",
      "iter = 8000 / 8000\n",
      "iter = 1000 / 8000\n",
      "iter = 2000 / 8000\n",
      "iter = 3000 / 8000\n",
      "iter = 4000 / 8000\n",
      "iter = 5000 / 8000\n",
      "iter = 6000 / 8000\n",
      "iter = 7000 / 8000\n",
      "iter = 8000 / 8000\n",
      "iter = 1000 / 8000\n",
      "iter = 2000 / 8000\n",
      "iter = 3000 / 8000\n",
      "iter = 4000 / 8000\n",
      "iter = 5000 / 8000\n",
      "iter = 6000 / 8000\n",
      "iter = 7000 / 8000\n",
      "iter = 8000 / 8000\n",
      "iter = 1000 / 8000\n",
      "iter = 2000 / 8000\n",
      "iter = 3000 / 8000\n",
      "iter = 4000 / 8000\n",
      "iter = 5000 / 8000\n",
      "iter = 6000 / 8000\n",
      "iter = 7000 / 8000\n",
      "iter = 8000 / 8000\n"
     ]
    }
   ],
   "source": [
    "# run model with uninformative prior for 4 different chains\n",
    "n_chains = 4\n",
    "seeds = [111, 199, 204, 421] \n",
    "\n",
    "B_list = []\n",
    "Z_list = []\n",
    "sigma2_list = []\n",
    "\n",
    "for sd in seeds:\n",
    "    sample_dict = run_mcmc_pg_hier(\n",
    "        X_train_scaled, y_train, ids_train,\n",
    "        sigma0=10,\n",
    "        n_iter=8000,\n",
    "        burn_in=2000,\n",
    "        a0=0.001, b0=0.001,\n",
    "        seed=sd\n",
    "    )\n",
    "    B_list.append(sample_dict[\"B\"])\n",
    "    Z_list.append(sample_dict[\"Z\"])\n",
    "    sigma2_list.append(sample_dict[\"sigma2_b\"])\n",
    "\n",
    "# stack the results to the form of chain\n",
    "B_samples = np.stack(B_list, axis=0)\n",
    "Z_samples = np.stack(Z_list, axis=0) \n",
    "sigma2_samples = np.stack(sigma2_list, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "599b1abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median ESS of beta samples: 23699.78046032766\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max R-hat of beta samples: 1.03799448863863\n"
     ]
    }
   ],
   "source": [
    "# compute the effective sample size of beta\n",
    "import arviz as az\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "C, S, p = B_samples.shape\n",
    "\n",
    "beta_da = xr.DataArray(\n",
    "    B_samples,\n",
    "    dims=(\"chain\", \"draw\", \"beta\")\n",
    ")\n",
    "\n",
    "# calculate ess and extract\n",
    "ess_beta_da = az.ess(beta_da)\n",
    "ess_beta = ess_beta_da[\"x\"].values\n",
    "print(\"median ESS of beta samples:\", np.median(ess_beta))\n",
    "\n",
    "plt.hist(ess_beta, bins=30)\n",
    "plt.xlabel(\"ESS\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"ESS distribution for all beta\")\n",
    "plt.show()\n",
    "\n",
    "# R-hat to analyse the var / convergence\n",
    "rhat_beta_da = az.rhat(beta_da)\n",
    "rhat_beta = rhat_beta_da[\"x\"].values\n",
    "print(\"max R-hat of beta samples:\", np.max(rhat_beta))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7862d7",
   "metadata": {},
   "source": [
    "We could see from the histogram that for a very large proportion of features, the effective sample size are close to the total number of post-burnin iterations, suggesting well mixing and independent posterior samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4774c912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_16bd4\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th id=\"T_16bd4_level0_col0\" class=\"col_heading level0 col0\" >index</th>\n",
       "      <th id=\"T_16bd4_level0_col1\" class=\"col_heading level0 col1\" >feature</th>\n",
       "      <th id=\"T_16bd4_level0_col2\" class=\"col_heading level0 col2\" >PIP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td id=\"T_16bd4_row0_col0\" class=\"data row0 col0\" >2</td>\n",
       "      <td id=\"T_16bd4_row0_col1\" class=\"data row0 col1\" >first_hosp_stay</td>\n",
       "      <td id=\"T_16bd4_row0_col2\" class=\"data row0 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_16bd4_row1_col0\" class=\"data row1 col0\" >119</td>\n",
       "      <td id=\"T_16bd4_row1_col1\" class=\"data row1 col1\" >urineoutput</td>\n",
       "      <td id=\"T_16bd4_row1_col2\" class=\"data row1 col2\" >1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_16bd4_row2_col0\" class=\"data row2 col0\" >70</td>\n",
       "      <td id=\"T_16bd4_row2_col1\" class=\"data row2 col1\" >heart_rate_max</td>\n",
       "      <td id=\"T_16bd4_row2_col2\" class=\"data row2 col2\" >0.986292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_16bd4_row3_col0\" class=\"data row3 col0\" >112</td>\n",
       "      <td id=\"T_16bd4_row3_col1\" class=\"data row3 col1\" >temperature_max_1</td>\n",
       "      <td id=\"T_16bd4_row3_col2\" class=\"data row3 col2\" >0.877833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_16bd4_row4_col0\" class=\"data row4 col0\" >111</td>\n",
       "      <td id=\"T_16bd4_row4_col1\" class=\"data row4 col1\" >temperature_min_1</td>\n",
       "      <td id=\"T_16bd4_row4_col2\" class=\"data row4 col2\" >0.876958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_16bd4_row5_col0\" class=\"data row5 col0\" >140</td>\n",
       "      <td id=\"T_16bd4_row5_col1\" class=\"data row5 col1\" >race_HISPANIC/LATINO - HONDURAN</td>\n",
       "      <td id=\"T_16bd4_row5_col2\" class=\"data row5 col2\" >0.840458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_16bd4_row6_col0\" class=\"data row6 col0\" >86</td>\n",
       "      <td id=\"T_16bd4_row6_col1\" class=\"data row6 col1\" >temperature_mean</td>\n",
       "      <td id=\"T_16bd4_row6_col2\" class=\"data row6 col2\" >0.793833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_16bd4_row7_col0\" class=\"data row7 col0\" >16</td>\n",
       "      <td id=\"T_16bd4_row7_col1\" class=\"data row7 col1\" >albumin_max</td>\n",
       "      <td id=\"T_16bd4_row7_col2\" class=\"data row7 col2\" >0.709417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_16bd4_row8_col0\" class=\"data row8 col0\" >62</td>\n",
       "      <td id=\"T_16bd4_row8_col1\" class=\"data row8 col1\" >bilirubin_total_max</td>\n",
       "      <td id=\"T_16bd4_row8_col2\" class=\"data row8 col2\" >0.689750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_16bd4_row9_col0\" class=\"data row9 col0\" >65</td>\n",
       "      <td id=\"T_16bd4_row9_col1\" class=\"data row9 col1\" >ck_mb_min</td>\n",
       "      <td id=\"T_16bd4_row9_col2\" class=\"data row9 col2\" >0.612125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_16bd4_row10_col0\" class=\"data row10 col0\" >163</td>\n",
       "      <td id=\"T_16bd4_row10_col1\" class=\"data row10 col1\" >admission_location_INTERNAL TRANSFER TO OR FROM PSYCH</td>\n",
       "      <td id=\"T_16bd4_row10_col2\" class=\"data row10 col2\" >0.590583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_16bd4_row11_col0\" class=\"data row11 col0\" >0</td>\n",
       "      <td id=\"T_16bd4_row11_col1\" class=\"data row11 col1\" >admission_age</td>\n",
       "      <td id=\"T_16bd4_row11_col2\" class=\"data row11 col2\" >0.568750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_16bd4_row12_col0\" class=\"data row12 col0\" >3</td>\n",
       "      <td id=\"T_16bd4_row12_col1\" class=\"data row12 col1\" >icustay_seq</td>\n",
       "      <td id=\"T_16bd4_row12_col2\" class=\"data row12 col2\" >0.541917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td id=\"T_16bd4_row13_col0\" class=\"data row13 col0\" >150</td>\n",
       "      <td id=\"T_16bd4_row13_col1\" class=\"data row13 col1\" >race_WHITE - BRAZILIAN</td>\n",
       "      <td id=\"T_16bd4_row13_col2\" class=\"data row13 col2\" >0.504250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x118dc2150>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average over chains to compute the posterior inclusion probability\n",
    "pip_all = Z_samples.mean(axis=(0, 1))\n",
    "\n",
    "# extract the important features suggested by the model\n",
    "feature_idx = np.where(pip_all > 0.5)[0]\n",
    "feature_names_np = np.array(feature_names)\n",
    "\n",
    "pip_table = pd.DataFrame({\n",
    "    \"index\": feature_idx,\n",
    "    \"feature\": feature_names_np[feature_idx],\n",
    "    \"PIP\": pip_all[feature_idx]\n",
    "})\n",
    "\n",
    "pip_table = pip_table.sort_values(\"PIP\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "pip_table.style.hide(axis=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7482463",
   "metadata": {},
   "source": [
    "This enjoys a large overlap with our XGBoost result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8253b085",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC by Polya-Gamma hierarchical model: 0.7116964707331594\n"
     ]
    }
   ],
   "source": [
    "# posterior predictive check\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "C, S, p = B_samples.shape\n",
    "n_test = X_test_scaled.shape[0]\n",
    "n_subj_test = len(uniq_test)\n",
    "\n",
    "# flatten over all chains\n",
    "B_flat = B_samples.reshape(-1, p)\n",
    "Z_flat = Z_samples.reshape(-1, p)\n",
    "sigma2_flat = sigma2_samples.reshape(-1)\n",
    "S_total = B_flat.shape[0]\n",
    "\n",
    "# to store the prediction for test\n",
    "p_test_s = np.zeros((S_total, n_test))\n",
    "rng = np.random.default_rng(638)\n",
    "\n",
    "# predict by each sample\n",
    "for s in range(S_total):\n",
    "    # extract samples\n",
    "    beta_s = B_flat[s, :]\n",
    "    z_s = Z_flat[s, :]\n",
    "    sigma2_s = sigma2_flat[s]\n",
    "\n",
    "    # the actual predicted coefficient\n",
    "    beta_eff_s = beta_s * z_s\n",
    "\n",
    "    # assign a subject-specific randomness for each subject\n",
    "    b_new_subj = rng.normal(loc=0.0, scale=np.sqrt(sigma2_s), size=n_subj_test)\n",
    "    b_new_i = b_new_subj[ids_test]\n",
    "\n",
    "    # predict the bernoulli probability\n",
    "    eta_s = X_test_scaled @ beta_eff_s + b_new_i\n",
    "    p_test_s[s, :] = expit(eta_s)\n",
    "\n",
    "# mean among the predictions\n",
    "p_test_hat = p_test_s.mean(axis=0)\n",
    "\n",
    "# compute the auc for the prediction\n",
    "auc_pg   = roc_auc_score(y_test, p_test_hat)\n",
    "\n",
    "print(\"AUC by Polya-Gamma hierarchical model:\", auc_pg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb32049",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PoP_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
